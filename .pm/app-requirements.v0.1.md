# PDF 知识库 RAG 应用需求说明

## 项目概述

开发一个基于 RAG（检索增强生成）的应用程序，能够处理 PDF 文档，构建知识库，并通过 Web 界面允许用户查询文档内容，获取 LLM 生成的回答及原文引用。

## 核心功能需求

1. **文档处理**：

   - 读取指定目录中的所有 PDF 文件
   - 提取文本内容并进行分块处理
   - 生成文本嵌入向量并存储

2. **知识库构建**：

   - 使用 PGVector 作为向量数据库
   - 建立高效的检索索引
   - 保存文档元数据（如文件名、页码等）

3. **用户查询界面**：

   - 提供简洁的 Web 前端界面
   - 接收用户自然语言问题
   - 展示 LLM 回答及相关原文引用

4. **回答生成**：
   - 基于用户查询检索相关文档片段
   - 使用 LLM 生成连贯、准确的回答
   - 在回答中引用原始文档来源（文件名及相关段落）

## 技术栈

1. **后端**：

   - Python 3.9+
   - LlamaIndex：文档处理、索引构建和查询处理
   - PostgreSQL + PGVector：向量存储和相似度搜索
   - Python-dotenv：环境变量管理（LLM API 密钥等）

2. **前端**：

   - Gradio：构建简洁的 Web 用户界面

3. **LLM 集成**：

   - 通过.env 文件配置的 API 密钥和 BaseURL 连接外部 LLM 服务

4. **文档处理**：

   - PyPDF2/PDFMiner：PDF 文本提取
   - LlamaIndex 文档加载器和处理器
   - 支持混合检索(BM25 及稠密向量检索)及重排序

5. **部署**
   - 支持本地运行
   - 支持 docker 部署

## 实现思路

我们将创建一个极简但功能完整的 RAG 应用，包含以下核心组件：

1. 文档加载器：读取 PDF 文件并提取文本
2. 文本处理器：将文档分割成适当大小的块
3. 向量数据库连接器：使用 PGVector 存储嵌入
4. 检索引擎：基于用户查询找到相关文档片段
5. LLM 集成：生成回答并引用来源
6. Gradio 界面：提供用户交互功能

这个应用将允许用户上传 PDF 文档或指定包含 PDF 的目录，系统会处理这些文档并构建知识库。用户可以通过 Web 界面提问，系统会检索相关内容，使用 LLM 生成回答，并显示原文引用，帮助用户验证回答的准确性。
